{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pynq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpynq\u001b[39;00m \u001b[39mimport\u001b[39;00m Overlay\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpynq\u001b[39;00m \u001b[39mimport\u001b[39;00m allocate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pynq'"
     ]
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\plumy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython import display\n",
    "from time import time\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== function for validation =====\n",
    "\n",
    "def Validate_file(ourOutput, golden, size, fp):\n",
    "    \"\"\"\n",
    "    Validate the output of the HLS IP against the golden output\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    C, D, H, W = size[0], size[1], size[2], size[3]\n",
    "    for c in range(C):\n",
    "        for d in range(D):\n",
    "            for h in range(H):\n",
    "                for w in range(W):\n",
    "                    if ourOutput[c][d][h][w] != golden[c][d][h][w]:\n",
    "                        print(f'[ERROR]  result[{c+1:3.0f}][{d+1:3.0f}][{h+1:3.0f}][{w+1:3.0f}] = {ourOutput[c][d][h][w]:3.0f}, gold: {golden[c][d][h][w]:3.0f}, error: {ourOutput[c][d][h][w] - golden[c][d][h][w] }', file=fp)\n",
    "                        errors += 1\n",
    "    if(errors == 0):\n",
    "        print(f'Validation passed! all results are the same', file=fp)\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== function to load data from files =====\n",
    "\n",
    "def CountArr(filename):\n",
    "    \"\"\"\n",
    "    Count the number of data in the file \"filename\"\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        num = 0\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return num\n",
    "\n",
    "def LoadArr(filename, type):\n",
    "    \"\"\"\n",
    "    Load the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    num = CountArr(filename)\n",
    "    arr = allocate(shape=(num,), dtype=type)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        num = 0\n",
    "        while line:\n",
    "            arr[num] = type(np.float32(line))\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return arr\n",
    "\n",
    "def LoadNpArr(filename, type):\n",
    "    \"\"\"\n",
    "    Load the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    num = CountArr(filename)\n",
    "    arr = []\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        num = 0\n",
    "        while line:\n",
    "            arr = arr.append(type(np.float32(line)))\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return np.array(arr, dtype=type)\n",
    "\n",
    "def SaveNpArr(filename, arr):\n",
    "    \"\"\"\n",
    "    Save the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range(len(arr)):\n",
    "            print(arr[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== function about video =====\n",
    "\n",
    "def RecordVideo(mode='INF', length=0):\n",
    "    \"\"\"\n",
    "    Record video from the camera and return a numpy array\n",
    "    \"\"\"\n",
    "    # setup the camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Camera setting:')\n",
    "    print('  width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print('  height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print('  fps: ', cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    print('Start recording...')\n",
    "    # record video\n",
    "    frames = []\n",
    "\n",
    "    if (mode == 'FRAME'):\n",
    "        print('mode: FRAME, length:', length, 'frames')\n",
    "        ret, frame = cap.read()\n",
    "        while (len(frames) < length):\n",
    "            frames.append(frame)\n",
    "            ret, frame = cap.read()\n",
    "    else:\n",
    "        print('mode: INF, need to stop manually')\n",
    "        try:\n",
    "            ret, frame = cap.read()\n",
    "            while (ret == True):\n",
    "                frames.append(frame)\n",
    "                ret, frame = cap.read()\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "    cap.release()\n",
    "    print('Stop recording...')\n",
    "    return np.array(frames, dtype=np.uint8)\n",
    "\n",
    "def ShowVideo(frames, fps=30):\n",
    "    \"\"\"\n",
    "    Show the video in the notebook\n",
    "    \"\"\"\n",
    "    for i in range(len(frames)):\n",
    "        # some block magic\n",
    "        _, ret_array = cv2.imencode('.jpg', frames[i])\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(display.Image(data=ret_array))\n",
    "        sleep(1/fps)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allocate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# ===== allocate buffers =====\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m my_input \u001b[39m=\u001b[39m allocate(shape\u001b[39m=\u001b[39m(\u001b[39m602112\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n\u001b[0;32m      4\u001b[0m output \u001b[39m=\u001b[39m allocate(shape\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n\u001b[0;32m      6\u001b[0m X_stem_1 \u001b[39m=\u001b[39m allocate(shape\u001b[39m=\u001b[39m(\u001b[39m2257920\u001b[39m,), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'allocate' is not defined"
     ]
    }
   ],
   "source": [
    "# ===== allocate buffer_tensor_tensor_tensor_tensors =====\n",
    "\n",
    "my_input = allocate(shape=(602112), dtype=np.uint8)\n",
    "output = allocate(shape=(10,), dtype=np.uint8)\n",
    "\n",
    "X_stem_1 = allocate(shape=(2257920,), dtype=np.uint8)\n",
    "X_stem_2 = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X_data = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X2_data = allocate(shape=(802816,), dtype=np.uint8)\n",
    "X3_data = allocate(shape=(200704,), dtype=np.uint8)\n",
    "X_seq = allocate(shape=(50176,), dtype=np.uint8)\n",
    "X_tmp_data = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X_batch_data = allocate(shape=(7225344,), dtype=np.uint8)\n",
    "X_mid_data = allocate(shape=(7225344,), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== allocate and load kernel data =====\n",
    "\n",
    "Kernel_stem_0 = LoadArr('stem.0.weight.dat', np.int8)\n",
    "Kernel_stem_3 = LoadArr('stem.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq1_0_conv1_0_0 = LoadArr('layer1.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv2_0_0 = LoadArr('layer1.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv1_0_0 = LoadArr('layer1.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv2_0_0 = LoadArr('layer1.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv1_0_3 = LoadArr('layer1.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv2_0_3 = LoadArr('layer1.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv1_0_3 = LoadArr('layer1.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv2_0_3 = LoadArr('layer1.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq2_0_conv1_0_0 = LoadArr('layer2.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv1_0_3 = LoadArr('layer2.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv2_0_0 = LoadArr('layer2.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv2_0_3 = LoadArr('layer2.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_0_downsample_0 = LoadArr('layer2.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv1_0_0 = LoadArr('layer2.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv1_0_3 = LoadArr('layer2.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv2_0_0 = LoadArr('layer2.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv2_0_3 = LoadArr('layer2.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq3_0_conv1_0_0 = LoadArr('layer3.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv1_0_3 = LoadArr('layer3.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv2_0_0 = LoadArr('layer3.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv2_0_3 = LoadArr('layer3.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_0_downsample_0 = LoadArr('layer3.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv1_0_0 = LoadArr('layer3.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv1_0_3 = LoadArr('layer3.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv2_0_0 = LoadArr('layer3.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv2_0_3 = LoadArr('layer3.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq4_0_conv1_0_0 = LoadArr('layer4.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv1_0_3 = LoadArr('layer4.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv2_0_0 = LoadArr('layer4.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv2_0_3 = LoadArr('layer4.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_0_downsample_0 = LoadArr('layer4.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv1_0_0 = LoadArr('layer4.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv1_0_3 = LoadArr('layer4.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv2_0_0 = LoadArr('layer4.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv2_0_3 = LoadArr('layer4.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_linear = LoadArr('fc.1.weight.dat', np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== setup ip =====\n",
    "\n",
    "# load ip\n",
    "ol = Overlay(\"./bitstreams/r2plus1d_v11_full_CBR.bit\")\n",
    "ip_r2plus1d = ol.r2plus1d_0\n",
    "\n",
    "# write input address\n",
    "ip_r2plus1d.write(0x10, my_input.device_address)\n",
    "# write output address\n",
    "ip_r2plus1d.write(0x22C, output.device_address)\n",
    "# write kernel address\n",
    "ip_r2plus1d.write(0x1C, Kernel_stem_0.device_address)\n",
    "ip_r2plus1d.write(0x28, Kernel_stem_3.device_address)\n",
    "ip_r2plus1d.write(0x34, Kernel_seq1_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x40, Kernel_seq1_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x4C, Kernel_seq1_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x58, Kernel_seq1_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x64, Kernel_seq1_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x70, Kernel_seq1_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x7C, Kernel_seq1_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x88, Kernel_seq1_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x94, Kernel_seq2_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0xA0, Kernel_seq2_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0xAC, Kernel_seq2_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0xB8, Kernel_seq2_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0xC4, Kernel_seq2_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0xD0, Kernel_seq2_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0xDC, Kernel_seq2_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0xE8, Kernel_seq2_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0xF4, Kernel_seq2_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x100, Kernel_seq3_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x10C, Kernel_seq3_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x118, Kernel_seq3_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x124, Kernel_seq3_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x130, Kernel_seq3_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0x13C, Kernel_seq3_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x148, Kernel_seq3_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x154, Kernel_seq3_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x160, Kernel_seq3_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x16C, Kernel_seq4_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x178, Kernel_seq4_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x184, Kernel_seq4_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x190, Kernel_seq4_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x19C, Kernel_seq4_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0x1A8, Kernel_seq4_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x1B4, Kernel_seq4_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x1C0, Kernel_seq4_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x1CC, Kernel_seq4_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x1D8, Kernel_linear.device_address)\n",
    "# write buffer address\n",
    "ip_r2plus1d.write(0x1E4, X_stem_1.device_address)      # stem.2 ouptut\n",
    "ip_r2plus1d.write(0x1F0, X_stem_2.device_address)      # layer1 output\n",
    "ip_r2plus1d.write(0x1FC, X_data.device_address)      \n",
    "ip_r2plus1d.write(0x208, X2_data.device_address)       # layer2 output\n",
    "ip_r2plus1d.write(0x214, X3_data.device_address)       # layer3 output\n",
    "ip_r2plus1d.write(0x220, X_seq.device_address)         # layer4 output\n",
    "ip_r2plus1d.write(0x238, X_tmp_data.device_address)    # layer1 output\n",
    "ip_r2plus1d.write(0x244, X_batch_data.device_address)  # layer1.1.relu input\n",
    "ip_r2plus1d.write(0x250, X_mid_data.device_address)    # layer1.1.conv2.0.2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera setting:\n",
      "  width:  640.0\n",
      "  height:  480.0\n",
      "  fps:  0.0\n",
      "Start recording...\n",
      "mode: INF, need to stop manually\n",
      "Stop recording...\n"
     ]
    }
   ],
   "source": [
    "# ===== recording input video =====\n",
    "\n",
    "# INF mode: need to interrupt manually\n",
    "# FRAME mode: need to set frame number\n",
    "input_video = RecordVideo(mode='INF')\n",
    "# input_video = RecordVideo(mode='FRAME', length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before cut: (7, 480, 640, 3)\n",
      "shape before cut: (4, 480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# ===== play and store input video =====\n",
    "\n",
    "# only for check\n",
    "ShowVideo(input_video, 30)\n",
    "\n",
    "# cut video to get middle part\n",
    "print('shape before cut:', input_video.shape)\n",
    "num_frame = input_video.shape[0]\n",
    "input_video = input_video[int(num_frame/5):int(num_frame*4/5)]\n",
    "print('shape before cut:', input_video.shape)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('record.mp4', fourcc, 30, (640, 480))\n",
    "\n",
    "for i in range(len(input_video)):\n",
    "    out.write(input_video[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(buffer_tensor): <class 'torch.Tensor'>\n",
      "buffer_tensor.shape: torch.Size([3, 16, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "# # ===== preprocess input video =====\n",
    "\n",
    "# def linspace_sampling(num_frames, num_samples):\n",
    "\n",
    "#     idx = list(np.linspace(0, num_frames-1, num_samples))\n",
    "#     frame_indices = [int(i) for i in idx]\n",
    "\n",
    "#     return frame_indices\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((112, 112)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "# ])\n",
    "\n",
    "# # initialize a VideoCapture object to read video data into a numpy array\n",
    "# capture = cv2.VideoCapture('12_Subject02Scene1rgb2_23.avi')\n",
    "# original_frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# # create a buffer. Must have dtype float, so it gets converted to a FloatTensor by Pytorch later\n",
    "\n",
    "# # Sampling\n",
    "# frame_count = 16\n",
    "# frame_indices = linspace_sampling(original_frame_count, frame_count)\n",
    "\n",
    "# buffer_tensor = torch.zeros(\n",
    "#     (frame_count, 3, 112, 112))\n",
    "\n",
    "# for i, v in enumerate(frame_indices):\n",
    "#     capture.set(cv2.CAP_PROP_POS_FRAMES, v)\n",
    "#     retaining, frame = capture.read()\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     frame = transform(frame)\n",
    "#     buffer_tensor[i] = frame\n",
    "\n",
    "# # release the VideoCapture once it is no longer needed\n",
    "# capture.release()\n",
    "\n",
    "# # convert from [D, H, W, C] format to [C, D, H, W] (what PyTorch uses)\n",
    "# # D = Depth (in this case, time), H = Height, W = Width, C = Channels\n",
    "# buffer_tensor = buffer_tensor.permute((1, 0, 2, 3))\n",
    "# print('type(buffer_tensor):', type(buffer_tensor))\n",
    "# print('buffer_tensor.shape:', buffer_tensor.shape)\n",
    "\n",
    "# # quantize\n",
    "# buffer_tensor = np.round(buffer_tensor * 3.75607810544967651e-02 + 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(buffer): <class 'numpy.ndarray'>\n",
      "buffer.shape: (3, 16, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "def linspace_sampling(num_frames, num_samples):\n",
    "\n",
    "    idx = list(np.linspace(0, num_frames-1, num_samples))\n",
    "    frame_indices = [int(i) for i in idx]\n",
    "\n",
    "    return frame_indices\n",
    "\n",
    "# initialize a VideoCapture object to read video data into a numpy array\n",
    "capture = cv2.VideoCapture('12_Subject02Scene1rgb2_23.avi')\n",
    "original_frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# create a buffer. Must have dtype float, so it gets converted to a FloatTensor by Pytorch later\n",
    "\n",
    "# Sampling\n",
    "frame_count = 16\n",
    "frame_indices = linspace_sampling(original_frame_count, frame_count)\n",
    "\n",
    "buffer = np.zeros(\n",
    "    (frame_count, 112, 112, 3))\n",
    "\n",
    "for i, v in enumerate(frame_indices):\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, v)\n",
    "    retaining, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # transform\n",
    "    frame = cv2.resize(frame, (112, 112), interpolation=cv2.INTER_AREA)\n",
    "    # normalize frame with mean = (0.485, 0.456, 0.406), and std = (0.229, 0.224, 0.225)\n",
    "    frame = frame.astype(np.float32)\n",
    "    frame = frame / 255.0\n",
    "    frame = (frame - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "    buffer[i] = frame\n",
    "\n",
    "# release the VideoCapture once it is no longer needed\n",
    "capture.release()\n",
    "\n",
    "# convert from [D, H, W, C] format to [C, D, H, W] (what PyTorch uses)\n",
    "# D = Depth (in this case, time), H = Height, W = Width, C = Channels\n",
    "buffer = np.swapaxes(buffer, 0, 3)\n",
    "buffer = np.swapaxes(buffer, 1, 3)\n",
    "buffer = np.swapaxes(buffer, 2, 3)\n",
    "print('type(buffer):', type(buffer))\n",
    "print('buffer.shape:', buffer.shape)\n",
    "\n",
    "# quantize\n",
    "buffer = np.round(buffer * 3.75607810544967651e-02 + 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer size =  (3, 16, 112, 112) buffer_tensor size =  torch.Size([3, 16, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "# # compare buffer and buffer_tensor\n",
    "# fp = open(\"buffer_compare.txt\", 'w')\n",
    "# print(\"buffer size = \", buffer.shape, \"buffer_tensor size = \", buffer_tensor.shape)\n",
    "# error = Validate_file(buffer, buffer_tensor, [3, 16, 112, 112], fp)\n",
    "# fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# ===== start prediction =====\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m my_input[:] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(buffer\u001b[39m.\u001b[39mreshape(\u001b[39m602112\u001b[39m))\n\u001b[0;32m      4\u001b[0m timeKernelStart \u001b[39m=\u001b[39m time()\n\u001b[0;32m      5\u001b[0m ip_r2plus1d\u001b[39m.\u001b[39mwrite(\u001b[39m0x00\u001b[39m, \u001b[39m0x01\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_input' is not defined"
     ]
    }
   ],
   "source": [
    "# ===== start prediction =====\n",
    "\n",
    "my_input[:] = np.array(buffer.reshape(602112))\n",
    "timeKernelStart = time()\n",
    "ip_r2plus1d.write(0x00, 0x01)\n",
    "\n",
    "# wait for the computation to finish\n",
    "while (ip_r2plus1d.read(0x00) & 0x4) == 0x0:\n",
    "    continue\n",
    "\n",
    "timeKernelEnd = time()\n",
    "print(\"hardware execution time: \" + str(timeKernelEnd - timeKernelStart) + \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# ===== show the result =====\n",
    "\n",
    "classes = ['Scroll_hand_towards_right',\n",
    "           'Scroll_hand_towards_left',\n",
    "           'Scroll_hand_downward',\n",
    "           'Scroll_hand_upward',\n",
    "           'Zoom_in_with_fists',\n",
    "           'Zoom_out_with_fists',\n",
    "           'Rotate_fists_clockwise',\n",
    "           'Rotate_fists_counterclockwise',\n",
    "           'Bring_hand_close',\n",
    "           ' Push_away']\n",
    "\n",
    "print('result:', classes[np.argmax(output)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa3a4132232ef57bd967da4f502201fad326f014cc6ad01b5db327eca3c579df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
