{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate data\n",
    "def Validate(ourOutput, golden, size):\n",
    "    errors = 0\n",
    "    N, C, D, H, W = size[0], size[1], size[2], size[3], size[4]\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for d in range(D):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        pos = n * C*D*H*W + c * D*H*W + d * H*W + h * W + w\n",
    "                        if ourOutput[pos] != golden[pos] and int(golden[pos]) != 0:\n",
    "                            print(f'[ERROR]  result[{n+1:3.0f}][{c+1:3.0f}][{d+1:3.0f}][{h+1:3.0f}][{w+1:3.0f}] = {ourOutput[pos]:3.0f}, gold: {golden[pos]:3.0f}, error: {100*(int(ourOutput[pos]) - int(golden[pos])) / int(golden[pos]):3.5f}%')\n",
    "                            errors += 1\n",
    "    return errors\n",
    "\n",
    "def Validate_file(ourOutput, golden, size, fp):\n",
    "    errors = 0\n",
    "    N, C, D, H, W = size[0], size[1], size[2], size[3], size[4]\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for d in range(D):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        pos = n * C*D*H*W + c * D*H*W + d * H*W + h * W + w\n",
    "                        if ourOutput[pos] != golden[pos] and int(golden[pos]) != 0:\n",
    "                            print(f'[ERROR]  result[{n+1:3.0f}][{c+1:3.0f}][{d+1:3.0f}][{h+1:3.0f}][{w+1:3.0f}] = {ourOutput[pos]:3.0f}, gold: {golden[pos]:3.0f}, error: {100*(int(ourOutput[pos]) - int(golden[pos])) / int(golden[pos]):3.5f}%', file=fp)\n",
    "                            errors += 1\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountArr(filename):\n",
    "    \"\"\"\n",
    "    Count the number of data in the file \"filename\"\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        num = 0\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return num\n",
    "\n",
    "def LoadArr(filename, type):\n",
    "    \"\"\"\n",
    "    Load the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    num = CountArr(filename)\n",
    "    arr = allocate(shape=(num,), dtype=type)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        num = 0\n",
    "        while line:\n",
    "            arr[num] = type(np.float32(line))\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return arr\n",
    "\n",
    "def LoadNpArr(filename, type):\n",
    "    \"\"\"\n",
    "    Load the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    num = CountArr(filename)\n",
    "    arr = []\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        num = 0\n",
    "        while line:\n",
    "            arr = arr.append(type(np.float32(line)))\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return np.array(arr, dtype=type)\n",
    "\n",
    "def SaveNpArr(filename, arr):\n",
    "    \"\"\"\n",
    "    Save the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range(len(arr)):\n",
    "            print(arr[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate buffers\n",
    "output = allocate(shape=(10,), dtype=np.uint8)\n",
    "\n",
    "X_stem_1 = allocate(shape=(2257920,), dtype=np.uint8)\n",
    "X_stem_2 = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X_data = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X2_data = allocate(shape=(802816,), dtype=np.uint8)\n",
    "X3_data = allocate(shape=(200704,), dtype=np.uint8)\n",
    "X_seq = allocate(shape=(50176,), dtype=np.uint8)\n",
    "X_tmp_data = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X_batch_data = allocate(shape=(7225344,), dtype=np.uint8)\n",
    "X_mid_data = allocate(shape=(7225344,), dtype=np.uint8)\n",
    "cnt = allocate(shape=(2,), dtype=np.int16)\n",
    "cnt[0], cnt[1] = -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate data\n",
    "\n",
    "Kernel_stem_0 = LoadArr('stem.0.weight.dat', np.int8)\n",
    "Kernel_stem_3 = LoadArr('stem.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq1_0_conv1_0_0 = LoadArr('layer1.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv2_0_0 = LoadArr('layer1.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv1_0_0 = LoadArr('layer1.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv2_0_0 = LoadArr('layer1.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv1_0_3 = LoadArr('layer1.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv2_0_3 = LoadArr('layer1.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv1_0_3 = LoadArr('layer1.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv2_0_3 = LoadArr('layer1.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq2_0_conv1_0_0 = LoadArr('layer2.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv1_0_3 = LoadArr('layer2.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv2_0_0 = LoadArr('layer2.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv2_0_3 = LoadArr('layer2.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_0_downsample_0 = LoadArr('layer2.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv1_0_0 = LoadArr('layer2.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv1_0_3 = LoadArr('layer2.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv2_0_0 = LoadArr('layer2.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv2_0_3 = LoadArr('layer2.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq3_0_conv1_0_0 = LoadArr('layer3.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv1_0_3 = LoadArr('layer3.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv2_0_0 = LoadArr('layer3.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv2_0_3 = LoadArr('layer3.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_0_downsample_0 = LoadArr('layer3.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv1_0_0 = LoadArr('layer3.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv1_0_3 = LoadArr('layer3.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv2_0_0 = LoadArr('layer3.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv2_0_3 = LoadArr('layer3.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq4_0_conv1_0_0 = LoadArr('layer4.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv1_0_3 = LoadArr('layer4.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv2_0_0 = LoadArr('layer4.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv2_0_3 = LoadArr('layer4.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_0_downsample_0 = LoadArr('layer4.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv1_0_0 = LoadArr('layer4.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv1_0_3 = LoadArr('layer4.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv2_0_0 = LoadArr('layer4.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv2_0_3 = LoadArr('layer4.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_linear = LoadArr('fc.1.weight.dat', np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input and output data\n",
    "my_input = LoadArr('input.dat', np.uint8)\n",
    "output_golden = LoadArr('output.dat', np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model\n",
    "# load ip\n",
    "ol = Overlay(\"./bitstreams/r2plus1d_v11_full_CBR.bit\")\n",
    "ip_r2plus1d = ol.r2plus1d_0\n",
    "\n",
    "# write input address\n",
    "ip_r2plus1d.write(0x10, my_input.device_address)\n",
    "# write output address\n",
    "ip_r2plus1d.write(0x22C, output.device_address)\n",
    "# write kernel address\n",
    "ip_r2plus1d.write(0x1C, Kernel_stem_0.device_address)\n",
    "ip_r2plus1d.write(0x28, Kernel_stem_3.device_address)\n",
    "ip_r2plus1d.write(0x34, Kernel_seq1_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x40, Kernel_seq1_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x4C, Kernel_seq1_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x58, Kernel_seq1_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x64, Kernel_seq1_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x70, Kernel_seq1_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x7C, Kernel_seq1_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x88, Kernel_seq1_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x94, Kernel_seq2_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0xA0, Kernel_seq2_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0xAC, Kernel_seq2_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0xB8, Kernel_seq2_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0xC4, Kernel_seq2_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0xD0, Kernel_seq2_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0xDC, Kernel_seq2_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0xE8, Kernel_seq2_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0xF4, Kernel_seq2_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x100, Kernel_seq3_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x10C, Kernel_seq3_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x118, Kernel_seq3_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x124, Kernel_seq3_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x130, Kernel_seq3_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0x13C, Kernel_seq3_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x148, Kernel_seq3_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x154, Kernel_seq3_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x160, Kernel_seq3_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x16C, Kernel_seq4_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x178, Kernel_seq4_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x184, Kernel_seq4_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x190, Kernel_seq4_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x19C, Kernel_seq4_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0x1A8, Kernel_seq4_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x1B4, Kernel_seq4_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x1C0, Kernel_seq4_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x1CC, Kernel_seq4_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x1D8, Kernel_linear.device_address)\n",
    "# write buffer address\n",
    "ip_r2plus1d.write(0x1E4, X_stem_1.device_address)      # stem.2 ouptut\n",
    "ip_r2plus1d.write(0x1F0, X_stem_2.device_address)      # layer1 output\n",
    "ip_r2plus1d.write(0x1FC, X_data.device_address)      \n",
    "ip_r2plus1d.write(0x208, X2_data.device_address)       # layer2 output\n",
    "ip_r2plus1d.write(0x214, X3_data.device_address)       # layer3 output\n",
    "ip_r2plus1d.write(0x220, X_seq.device_address)         # layer4 output\n",
    "ip_r2plus1d.write(0x238, X_tmp_data.device_address)    # layer1 output\n",
    "ip_r2plus1d.write(0x244, X_batch_data.device_address)  # layer1.1.relu input\n",
    "ip_r2plus1d.write(0x250, X_mid_data.device_address)    # layer1.1.conv2.0.2 output\n",
    "ip_r2plus1d.write(0x25C, cnt.device_address)    # help to count time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [\"layer_4_7\", \"layer_4_8\", \"end\"]\n",
    "action_list = [\"computation\", \"load kernel\", \"load X_data\", \"store Y_data\"]\n",
    "record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hardware execution time: 567.9108505249023 s\n"
     ]
    }
   ],
   "source": [
    "# start computation\n",
    "# start the computation for hls hardware\n",
    "timeKernelStart = time()\n",
    "pre_time ,now_time, compute_tmp = timeKernelStart, timeKernelStart, 0\n",
    "pre_cnt = [-1, -1]\n",
    "ip_r2plus1d.write(0x00, 0x01)\n",
    "# wait for the computation to finish\n",
    "while (ip_r2plus1d.read(0x00) & 0x4) == 0x0:\n",
    "    if(cnt[0] != pre_cnt[0]): # to next layer\n",
    "        now_time = time()\n",
    "        compute_tmp += now_time-pre_time\n",
    "        pre_time = now_time\n",
    "        \n",
    "        if(cnt[0] != 0):\n",
    "            record.append({action_list[0]: str(compute_tmp)})\n",
    "            compute_tmp = 0\n",
    "        \n",
    "        record.append({\"layer\": str(layer_list[cnt[0]])})\n",
    "        pre_cnt[0] = cnt[0]\n",
    "    \n",
    "    elif(cnt[1] != pre_cnt[1]):\n",
    "        now_time = time()\n",
    "        if pre_cnt[1] == 0:\n",
    "            compute_tmp += now_time-pre_time\n",
    "        elif pre_cnt[1] != -1:\n",
    "            record.append({action_list[pre_cnt[1]]: str(now_time-pre_time)})\n",
    "        pre_time = now_time\n",
    "        pre_cnt[1] = cnt[1]\n",
    "        \n",
    "timeKernelEnd = time()\n",
    "\n",
    "print(\"hardware execution time: \" + str(timeKernelEnd - timeKernelStart) + \" s\")\n",
    "\n",
    "# sum all action time in record\n",
    "record.append(\"\\n\\n >> the sum of every action time\")\n",
    "for j in range(len(action_list)):\n",
    "    sum = 0\n",
    "    for i in range(len(record)):\n",
    "        if action_list[j] in record[i]:\n",
    "            sum += float(record[i][action_list[j]])\n",
    "    record.append({action_list[j]: str(sum)})\n",
    "\n",
    "# store the time record to txt file\n",
    "with open(\"./record.txt\", 'w') as f:\n",
    "        for i in range(len(record)):\n",
    "            # check if the record is a dict\n",
    "            if isinstance(record[i], dict):\n",
    "                for key, value in record[i].items():\n",
    "                    print(key + \": \" + value, file=f)\n",
    "            else:\n",
    "                print(record[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAIL] There are some errors QQ, error rate:  0.8\n"
     ]
    }
   ],
   "source": [
    "# validate the result\n",
    "fp = open(\"results.txt\", 'w')\n",
    "errors = Validate_file(output, output_golden, [1, 10, 1, 1, 1], fp)\n",
    "if errors:\n",
    "    print(\"[FAIL] There are some errors QQ, error rate: \", errors / 10)\n",
    "else:\n",
    "    print(\"[PASS] Congratulation! All results are correct\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAIL] There are some errors QQ, error rate:  0.05684878117913832\n"
     ]
    }
   ],
   "source": [
    "output_golden = LoadArr('output_layer4.1.conv2.0.2.dat', np.uint8)\n",
    "fp = open(\"results.txt\", 'w')\n",
    "errors = Validate_file(X_mid_data, output_golden, [1, 1152, 2, 7, 7], fp)\n",
    "if errors:\n",
    "    print(\"[FAIL] There are some errors QQ, error rate: \", errors / 112896)\n",
    "else:\n",
    "    print(\"[PASS] Congratulation! All results are correct\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveNpArr(\"./MiddleData/X_stem_1.txt\", X_stem_1)\n",
    "SaveNpArr(\"./MiddleData/X_stem_2.txt\", X_stem_2)\n",
    "SaveNpArr(\"./MiddleData/X_data.txt\", X_data)\n",
    "SaveNpArr(\"./MiddleData/X_mid_data.txt\", X_mid_data)\n",
    "SaveNpArr(\"./MiddleData/X_batch_data.txt\", X_batch_data)\n",
    "SaveNpArr(\"./MiddleData/X_tmp_data.txt\", X_tmp_data)\n",
    "SaveNpArr(\"./MiddleData/X2_data.txt\", X2_data)\n",
    "SaveNpArr(\"./MiddleData/X3_data.txt\", X3_data)\n",
    "SaveNpArr(\"./MiddleData/X_seq.txt\", X_seq)\n",
    "SaveNpArr(\"./MiddleData/X_seq.txt\", X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa3a4132232ef57bd967da4f502201fad326f014cc6ad01b5db327eca3c579df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
