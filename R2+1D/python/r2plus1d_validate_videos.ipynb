{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from IPython import display\n",
    "from time import time\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== function for validation =====\n",
    "\n",
    "def Validate_file(ourOutput, golden, size, fp):\n",
    "    \"\"\"\n",
    "    Validate the output of the HLS IP against the golden output\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    N, C, D, H, W = size[0], size[1], size[2], size[3], size[4]\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for d in range(D):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        pos = n * C*D*H*W + c * D*H*W + d * H*W + h * W + w\n",
    "                        if ourOutput[pos] != golden[pos]:\n",
    "                            print(f'[ERROR]  result[{n+1:3.0f}][{c+1:3.0f}][{d+1:3.0f}][{h+1:3.0f}][{w+1:3.0f}] = {ourOutput[pos]:3.0f}, gold: {golden[pos]:3.0f}, error: {ourOutput[pos] - golden[pos]}', file=fp)\n",
    "                            errors += 1\n",
    "    if(errors == 0):\n",
    "        print(f'Validation passed! all results are the same', file=fp)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== function to load data from files =====\n",
    "\n",
    "def CountArr(filename):\n",
    "    \"\"\"\n",
    "    Count the number of data in the file \"filename\"\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        num = 0\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return num\n",
    "\n",
    "def LoadArr(filename, type):\n",
    "    \"\"\"\n",
    "    Load the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    num = CountArr(filename)\n",
    "    arr = allocate(shape=(num,), dtype=type)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        num = 0\n",
    "        while line:\n",
    "            arr[num] = type(np.float32(line))\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return arr\n",
    "\n",
    "def LoadNpArr(filename, type):\n",
    "    \"\"\"\n",
    "    Load the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    num = CountArr(filename)\n",
    "    arr = []\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        num = 0\n",
    "        while line:\n",
    "            arr = arr.append(type(np.float32(line)))\n",
    "            num += 1\n",
    "            line = f.readline()\n",
    "    return np.array(arr, dtype=type)\n",
    "\n",
    "def SaveNpArr(filename, arr):\n",
    "    \"\"\"\n",
    "    Save the data array from the file \"filename\" into a PL numpy array of type \"type\"\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range(len(arr)):\n",
    "            print(arr[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== function about video =====\n",
    "\n",
    "def RecordVideo(mode='INF', length=0):\n",
    "    \"\"\"\n",
    "    Record video from the camera and return a numpy array\n",
    "    \"\"\"\n",
    "    # setup the camera\n",
    "    cap = cv2.VideoCapture(-1)\n",
    "    print('Camera setting:')\n",
    "    print('  width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print('  height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print('  fps: ', cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    print('Start recording...')\n",
    "    # record video\n",
    "    frames = []\n",
    "\n",
    "    if (mode == 'FRAME'):\n",
    "        print('mode: FRAME, length:', length, 'frames')\n",
    "        ret, frame = cap.read()\n",
    "        while (len(frames) < length):\n",
    "            frames.append(frame)\n",
    "            ret, frame = cap.read()\n",
    "    else:\n",
    "        print('mode: INF, need to stop manually')\n",
    "        try:\n",
    "            ret, frame = cap.read()\n",
    "            while (ret == True):\n",
    "                frames.append(frame)\n",
    "                ret, frame = cap.read()\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "    cap.release()\n",
    "    print('Stop recording...')\n",
    "    return np.array(frames, dtype=np.uint8)\n",
    "\n",
    "def ShowVideo(frames, fps=30):\n",
    "    \"\"\"\n",
    "    Show the video in the notebook\n",
    "    \"\"\"\n",
    "    for i in range(len(frames)):\n",
    "        # some block magic\n",
    "        _, ret_array = cv2.imencode('.jpg', frames[i])\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(display.Image(data=ret_array))\n",
    "        sleep(1/fps)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== allocate buffer_tensor_tensor_tensor_tensors =====\n",
    "\n",
    "my_input = allocate(shape=(602112), dtype=np.uint8)\n",
    "output = allocate(shape=(10,), dtype=np.uint8)\n",
    "\n",
    "X_stem_1 = allocate(shape=(2257920,), dtype=np.uint8)\n",
    "X_stem_2 = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X_data = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X2_data = allocate(shape=(802816,), dtype=np.uint8)\n",
    "X3_data = allocate(shape=(200704,), dtype=np.uint8)\n",
    "X_seq = allocate(shape=(50176,), dtype=np.uint8)\n",
    "X_tmp_data = allocate(shape=(3211264,), dtype=np.uint8)\n",
    "X_batch_data = allocate(shape=(7225344,), dtype=np.uint8)\n",
    "X_mid_data = allocate(shape=(7225344,), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== allocate and load kernel data =====\n",
    "\n",
    "Kernel_stem_0 = LoadArr('stem.0.weight.dat', np.int8)\n",
    "Kernel_stem_3 = LoadArr('stem.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq1_0_conv1_0_0 = LoadArr('layer1.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv2_0_0 = LoadArr('layer1.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv1_0_0 = LoadArr('layer1.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv2_0_0 = LoadArr('layer1.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv1_0_3 = LoadArr('layer1.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_0_conv2_0_3 = LoadArr('layer1.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv1_0_3 = LoadArr('layer1.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq1_1_conv2_0_3 = LoadArr('layer1.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq2_0_conv1_0_0 = LoadArr('layer2.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv1_0_3 = LoadArr('layer2.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv2_0_0 = LoadArr('layer2.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_0_conv2_0_3 = LoadArr('layer2.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_0_downsample_0 = LoadArr('layer2.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv1_0_0 = LoadArr('layer2.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv1_0_3 = LoadArr('layer2.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv2_0_0 = LoadArr('layer2.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq2_1_conv2_0_3 = LoadArr('layer2.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq3_0_conv1_0_0 = LoadArr('layer3.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv1_0_3 = LoadArr('layer3.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv2_0_0 = LoadArr('layer3.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_0_conv2_0_3 = LoadArr('layer3.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_0_downsample_0 = LoadArr('layer3.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv1_0_0 = LoadArr('layer3.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv1_0_3 = LoadArr('layer3.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv2_0_0 = LoadArr('layer3.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq3_1_conv2_0_3 = LoadArr('layer3.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_seq4_0_conv1_0_0 = LoadArr('layer4.0.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv1_0_3 = LoadArr('layer4.0.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv2_0_0 = LoadArr('layer4.0.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_0_conv2_0_3 = LoadArr('layer4.0.conv2.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_0_downsample_0 = LoadArr('layer4.0.downsample.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv1_0_0 = LoadArr('layer4.1.conv1.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv1_0_3 = LoadArr('layer4.1.conv1.0.3.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv2_0_0 = LoadArr('layer4.1.conv2.0.0.weight.dat', np.int8)\n",
    "Kernel_seq4_1_conv2_0_3 = LoadArr('layer4.1.conv2.0.3.weight.dat', np.int8)\n",
    "\n",
    "Kernel_linear = LoadArr('fc.1.weight.dat', np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== setup ip =====\n",
    "\n",
    "# load ip\n",
    "ol = Overlay(\"./bitstreams/r2plus1d_v15.5_cnt.bit\")\n",
    "ip_r2plus1d = ol.r2plus1d_0\n",
    "\n",
    "# write input address\n",
    "ip_r2plus1d.write(0x10, my_input.device_address)\n",
    "# write output address\n",
    "ip_r2plus1d.write(0x22C, output.device_address)\n",
    "# write kernel address\n",
    "ip_r2plus1d.write(0x1C, Kernel_stem_0.device_address)\n",
    "ip_r2plus1d.write(0x28, Kernel_stem_3.device_address)\n",
    "ip_r2plus1d.write(0x34, Kernel_seq1_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x40, Kernel_seq1_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x4C, Kernel_seq1_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x58, Kernel_seq1_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x64, Kernel_seq1_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x70, Kernel_seq1_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x7C, Kernel_seq1_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x88, Kernel_seq1_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x94, Kernel_seq2_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0xA0, Kernel_seq2_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0xAC, Kernel_seq2_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0xB8, Kernel_seq2_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0xC4, Kernel_seq2_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0xD0, Kernel_seq2_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0xDC, Kernel_seq2_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0xE8, Kernel_seq2_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0xF4, Kernel_seq2_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x100, Kernel_seq3_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x10C, Kernel_seq3_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x118, Kernel_seq3_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x124, Kernel_seq3_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x130, Kernel_seq3_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0x13C, Kernel_seq3_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x148, Kernel_seq3_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x154, Kernel_seq3_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x160, Kernel_seq3_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x16C, Kernel_seq4_0_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x178, Kernel_seq4_0_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x184, Kernel_seq4_0_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x190, Kernel_seq4_0_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x19C, Kernel_seq4_0_downsample_0.device_address)\n",
    "ip_r2plus1d.write(0x1A8, Kernel_seq4_1_conv1_0_0.device_address)\n",
    "ip_r2plus1d.write(0x1B4, Kernel_seq4_1_conv1_0_3.device_address)\n",
    "ip_r2plus1d.write(0x1C0, Kernel_seq4_1_conv2_0_0.device_address)\n",
    "ip_r2plus1d.write(0x1CC, Kernel_seq4_1_conv2_0_3.device_address)\n",
    "ip_r2plus1d.write(0x1D8, Kernel_linear.device_address)\n",
    "# write buffer address\n",
    "ip_r2plus1d.write(0x1E4, X_stem_1.device_address)      # stem.2 ouptut\n",
    "ip_r2plus1d.write(0x1F0, X_stem_2.device_address)      # layer1 output\n",
    "ip_r2plus1d.write(0x1FC, X_data.device_address)      \n",
    "ip_r2plus1d.write(0x208, X2_data.device_address)       # layer2 output\n",
    "ip_r2plus1d.write(0x214, X3_data.device_address)       # layer3 output\n",
    "ip_r2plus1d.write(0x220, X_seq.device_address)         # layer4 output\n",
    "ip_r2plus1d.write(0x238, X_tmp_data.device_address)    # layer1 output\n",
    "ip_r2plus1d.write(0x244, X_batch_data.device_address)  # layer1.1.relu input\n",
    "ip_r2plus1d.write(0x250, X_mid_data.device_address)    # layer1.1.conv2.0.2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(buffer): <class 'numpy.ndarray'>\n",
      "buffer.shape: (3, 16, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "def linspace_sampling(num_frames, num_samples):\n",
    "\n",
    "    idx = list(np.linspace(0, num_frames-1, num_samples))\n",
    "    frame_indices = [int(i) for i in idx]\n",
    "\n",
    "    return frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Rotate_fists_clockwise\n",
      "hardware execution time: 567.0028865337372 s\n"
     ]
    }
   ],
   "source": [
    "classes = ['Scroll_hand_towards_right',\n",
    "           'Scroll_hand_towards_left',\n",
    "           'Scroll_hand_downward',\n",
    "           'Scroll_hand_upward',\n",
    "           'Zoom_in_with_fists',\n",
    "           'Zoom_out_with_fists',\n",
    "           'Rotate_fists_clockwise',\n",
    "           'Rotate_fists_counterclockwise',\n",
    "           'Bring_hand_close',\n",
    "           ' Push_away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 12, 7, 9, 6, 12, 15, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "# read labels\n",
    "name_list = []\n",
    "label = []\n",
    "with open('validate_videos_label.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        name, l = line.split()\n",
    "        name_list.append(name)\n",
    "        label.append(int(l))\n",
    "# randomly choose 100 videos\n",
    "num_samples = 100\n",
    "idx = np.random.choice(len(name_list), num_samples, replace=False)\n",
    "name_list = [name_list[i] for i in idx]\n",
    "label = [label[i] for i in idx]\n",
    "# count the number of each class\n",
    "class_count = [0 for i in range(10)]\n",
    "for l in label:\n",
    "    class_count[l] += 1\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(name_list)):\n",
    "    # initialize a VideoCapture object to read video data into a numpy array\n",
    "    capture = cv2.VideoCapture('validate_videos/'+name_list[i])\n",
    "    original_frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # create a buffer. Must have dtype float, so it gets converted to a FloatTensor by Pytorch later\n",
    "\n",
    "    # Sampling\n",
    "    frame_count = 16\n",
    "    frame_indices = linspace_sampling(original_frame_count, frame_count)\n",
    "\n",
    "    buffer = np.zeros(\n",
    "        (frame_count, 112, 112, 3))\n",
    "\n",
    "    for j, v in enumerate(frame_indices):\n",
    "        capture.set(cv2.CAP_PROP_POS_FRAMES, v)\n",
    "        retaining, frame = capture.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # transform\n",
    "        frame = cv2.resize(frame, (112, 112), interpolation=cv2.INTER_AREA)\n",
    "        # normalize frame with mean = (0.485, 0.456, 0.406), and std = (0.229, 0.224, 0.225)\n",
    "        frame = frame.astype(np.float32)\n",
    "        frame = frame / 255.0\n",
    "        frame = (frame - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "        buffer[j] = frame\n",
    "\n",
    "    # release the VideoCapture once it is no longer needed\n",
    "    capture.release()\n",
    "\n",
    "    # convert from [D, H, W, C] format to [C, D, H, W] (what PyTorch uses)\n",
    "    # D = Depth (in this case, time), H = Height, W = Width, C = Channels\n",
    "    buffer = np.swapaxes(buffer, 0, 3)\n",
    "    buffer = np.swapaxes(buffer, 1, 3)\n",
    "    buffer = np.swapaxes(buffer, 2, 3)\n",
    "    print('type(buffer):', type(buffer))\n",
    "    print('buffer.shape:', buffer.shape)\n",
    "\n",
    "    # quantize\n",
    "    buffer = np.round(buffer / 3.75607810544967651e-02 + 56).flatten()\n",
    "    \n",
    "    # ===== start prediction =====\n",
    "    my_input[:] = np.array(buffer.reshape(602112))\n",
    "    timeKernelStart = time()\n",
    "    ip_r2plus1d.write(0x00, 0x01)\n",
    "\n",
    "    # wait for the computation to finish\n",
    "    while (ip_r2plus1d.read(0x00) & 0x4) == 0x0:\n",
    "        continue\n",
    "\n",
    "    timeKernelEnd = time()\n",
    "    if(classes[np.argmax(output)] == label[i]):\n",
    "        correct += 1\n",
    "    \n",
    "    fp = open(\"validate_videos_result.txt\", 'w')\n",
    "    print(\"current video number = \", i , \"\\ncorrect number = \", correct, file=fp)\n",
    "    fp.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
